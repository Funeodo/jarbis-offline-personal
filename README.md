# Jarbis â€“ Offline Personal AI Assistant

**Jarbis** is a local-first, privacy-respecting personal AI assistant that runs 100% offline.  
It's built in Python and designed for full control, persistent memory, and smart automation.

---

## ğŸ”§ Features (WIP)

- âœ… Fully local, no cloud dependency
- âœ… Persistent memory using MySQL (organized by date, topic, type)
- âœ… Flask-based API for local commands and memory updates
- ğŸ”„ LLM integration via [Ollama](https://ollama.com/) or [llama.cpp](https://github.com/ggerganov/llama.cpp)
- ğŸ”„ Agent orchestration planned (CrewAI or custom lightweight agent)
- ğŸ”„ Goal: semantic memory and vector search integration

---

## ğŸ“ Folder structure

- `app/`: core logic and backend
- `db/`: SQL schema
- `models/`: local LLM usage notes
- `docs/`: development notes, roadmap, ideas

---

## ğŸ“Œ Project Goals

- Build a modular, privacy-first AI assistant
- Run LLMs locally using GPU (RTX 4060 Ti)
- Integrate function calling, memory, and agents in one clean flow
- Collaborate and learn with others building similar tools

---

## ğŸ’¬ Want to Collaborate?

This is a solo learning project but I'm open to feedback, collaboration or just sharing progress.  
Check the [Issues](https://github.com/funeodo/jarbis-offline-personal/issues) or open a new one!

---

## ğŸ§  Tech Stack

- Python 3.x
- Flask
- MySQL
- Ollama / llama.cpp
- Possibly Supabase (if switching from MySQL for vector search)

---

## ğŸ“œ License

MIT License â€“ feel free to fork, reuse and build on it.
